{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import socket\n",
    "import requests \n",
    "import re\n",
    "import builtwith\n",
    "import random as rand\n",
    "from bs4 import BeautifulSoup\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_API_KEY = \"AIzaSyA7zJKCeBGXBJOxxMV0OnV25EwxNiMVVuM\"\n",
    "# used for Google Places API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecommerce_services_list = \"WooCommerce Shopify Magento PrestaShop OpenCart Wix Bigcommerce Shopware osCommerce Amazon\"\n",
    "#most popular ecommerce providesr\n",
    "#see github for a more comprehensive list that can be used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_media_keywords = [\"instagram\", \"facebook\",\"twitter\"]\n",
    "black_list_keywords = [\"nightclub\",\"ecommerce\",\"e-commerce\"]\n",
    "positive_keywords = [\"organic\",\"recycle\",\"recycling\",\"health\",\"artisan\", \"curate\", \"sustainable\", \"Michelin\", \"awards\",\"local\"]\n",
    "#used for discounting based off the details in the Algorithm section of the Underwriter's Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stores = ['store',\n",
    " 'shop',\n",
    " 'outlet',\n",
    " 'mart',\n",
    " 'boutique',\n",
    " 'emporium',\n",
    " 'bazaar',\n",
    " 'market',\n",
    " 'showroom',\n",
    " 'co-op',\n",
    " 'mall',\n",
    " 'galleria',\n",
    " 'exchange',\n",
    " 'bargains',\n",
    " 'botique']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'}\n",
    "#Used for pulling data from Beautiful Soup\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCustomerListDataFrame(add_samples=False):\n",
    "    raw_company_data = {'Company Name':[],'Company URL':[],'Company Address':[],'Has Ecommerce':False}\n",
    "    df = pd.DataFrame(raw_company_data)\n",
    "    \n",
    "\n",
    "    if (add_samples==True):\n",
    "        one = (\"Joe's Cafe\",\"http://www.joescafebrighton.com/\",\"Joe's Cafe, 24 Upper Hamilton Rd, Brighton BN1 5DF\", \"not\")\n",
    "        two = (\"Moksha Caffe\", \"https://mokshacaffe.co.uk/\",\"4-5 York Pl, Brighton BN1 4GU\", \"is\")\n",
    "        three = (\"Cafe Coho\" ,\"https://www.cafecoho.co.uk/\",\"83a Queens Rd, Brighton BN1 3XE\",\"is\")\n",
    "        four = (\"Lovefit\",\"https://www.lovefit.co.uk/\",\"110 Queens Rd, Brighton BN1 3XF\",\"not\")\n",
    "        five = (\"Porter and York\",\"https://porterandyork.com/\",\"None\",\"is\")\n",
    "        six = (\"Dineamic\", \"https://www.dineamic.com.au/\",\"None\",\"is\")\n",
    "        seven = (\"Haus London\",\"https://hauslondon.com/\",\"None\",\"is\")\n",
    "        eight = (\"The Critical Slide Society\", \"https://www.thecriticalslidesociety.eu/\",\"None\",\"is\")\n",
    "        nine = (\"Studio Proper\",\"https://www.studioproper.com/\",\"None\",\"is\")\n",
    "        ten = (\"Tluxe\",\"https://www.tluxe.com/\",\"None\", \"is\")\n",
    "        eleven = (\"Cafe Coho Churchill Square\",\"https://new.brighton-hove.gov.uk/\",\"Russell Pl, Brighton BN1 2RG\",\"not\")\n",
    "        total = [one,two,three,four,five,six,seven,eight,nine,ten,eleven]\n",
    "        \n",
    "        \n",
    "        for number in total:\n",
    "            has_e = False\n",
    "            if number[3] == \"is\":\n",
    "                has_e = True\n",
    "            df = df.append({'Company Name':number[0],'Company URL': number[1],'Company Address':number[2],'Has Ecommerce':has_e},ignore_index=True)\n",
    "    #Creates a base Data Frame and a number of Dummy companies for testing\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company URL</th>\n",
       "      <th>Company Address</th>\n",
       "      <th>Has Ecommerce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Joe's Cafe</td>\n",
       "      <td>http://www.joescafebrighton.com/</td>\n",
       "      <td>Joe's Cafe, 24 Upper Hamilton Rd, Brighton BN1...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Moksha Caffe</td>\n",
       "      <td>https://mokshacaffe.co.uk/</td>\n",
       "      <td>4-5 York Pl, Brighton BN1 4GU</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Cafe Coho</td>\n",
       "      <td>https://www.cafecoho.co.uk/</td>\n",
       "      <td>83a Queens Rd, Brighton BN1 3XE</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Lovefit</td>\n",
       "      <td>https://www.lovefit.co.uk/</td>\n",
       "      <td>110 Queens Rd, Brighton BN1 3XF</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Porter and York</td>\n",
       "      <td>https://porterandyork.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Dineamic</td>\n",
       "      <td>https://www.dineamic.com.au/</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Haus London</td>\n",
       "      <td>https://hauslondon.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>The Critical Slide Society</td>\n",
       "      <td>https://www.thecriticalslidesociety.eu/</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Studio Proper</td>\n",
       "      <td>https://www.studioproper.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Tluxe</td>\n",
       "      <td>https://www.tluxe.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Cafe Coho Churchill Square</td>\n",
       "      <td>https://new.brighton-hove.gov.uk/</td>\n",
       "      <td>Russell Pl, Brighton BN1 2RG</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Company Name                              Company URL  \\\n",
       "0                   Joe's Cafe         http://www.joescafebrighton.com/   \n",
       "1                 Moksha Caffe               https://mokshacaffe.co.uk/   \n",
       "2                    Cafe Coho              https://www.cafecoho.co.uk/   \n",
       "3                      Lovefit               https://www.lovefit.co.uk/   \n",
       "4              Porter and York               https://porterandyork.com/   \n",
       "5                     Dineamic             https://www.dineamic.com.au/   \n",
       "6                  Haus London                  https://hauslondon.com/   \n",
       "7   The Critical Slide Society  https://www.thecriticalslidesociety.eu/   \n",
       "8                Studio Proper            https://www.studioproper.com/   \n",
       "9                        Tluxe                   https://www.tluxe.com/   \n",
       "10  Cafe Coho Churchill Square        https://new.brighton-hove.gov.uk/   \n",
       "\n",
       "                                      Company Address  Has Ecommerce  \n",
       "0   Joe's Cafe, 24 Upper Hamilton Rd, Brighton BN1...          False  \n",
       "1                       4-5 York Pl, Brighton BN1 4GU           True  \n",
       "2                     83a Queens Rd, Brighton BN1 3XE           True  \n",
       "3                     110 Queens Rd, Brighton BN1 3XF          False  \n",
       "4                                                None           True  \n",
       "5                                                None           True  \n",
       "6                                                None           True  \n",
       "7                                                None           True  \n",
       "8                                                None           True  \n",
       "9                                                None           True  \n",
       "10                       Russell Pl, Brighton BN1 2RG          False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateCustomerListDataFrame(add_samples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyseCustomerListDataFrame(df,add_colours=False):\n",
    "    \n",
    "    df['Text from Website'] = df['Company URL'].apply(getSoupfromURL)\n",
    "    ### Here is the Soup\n",
    "    \n",
    "    \n",
    "\n",
    "    df['Ecommerce Tags Found Score'] = df['Text from Website'].apply(getEcommerceTagScore)\n",
    "    #\n",
    "    df['Ecommerce IPs Found Score'] = df['Company URL'].apply(getEcommerceIPsScore)\n",
    "    df[\"Builtwith's Ecommerce-Detection Score\"] = df['Company URL'].apply(getBuiltWithEcommerceScore)\n",
    "    df['Ecommerce Domain URL Component Score'] = df['Company URL'].apply(checkURLComponents)\n",
    "    df['Ecommerce Detection Total Score'] = df['Ecommerce Tags Found Score'] +  df['Ecommerce IPs Found Score'] + df[\"Builtwith's Ecommerce-Detection Score\"]\n",
    "    df['Google Rating Aggregate'] = 0\n",
    "    df['Hygiene Rating'] = 0\n",
    "    df= getGoogleRatings(df)\n",
    "    df= getKeyWordsScore(df)\n",
    "    df = getHygieneRating(df)\n",
    "\n",
    "    df['Base Price'] = rand.randint(100,10000)\n",
    "    df['Discounted Price'] = df['Base Price']\n",
    "    df = getHygieneRating(df)\n",
    "    df = getDiscountedPrice(df)\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        index = row[0]\n",
    "\n",
    "        if (df['Google Rating Aggregate'][index] == 0 or df['Google Rating Aggregate'][index] == -1 ):\n",
    "            df['Google Rating Aggregate'][index] = \"None\"\n",
    "\n",
    "    \n",
    "    #df['Social Media Keywords'] = \n",
    "    #Positive Key Words \n",
    "    #df['Black List Keywords']\n",
    "#     if (add_colours == True):\n",
    "#         return applyColouring()\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoupfromURL(url):\n",
    "    return BeautifulSoup(requests.get(url,headers=agent).content).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateEcommerceListDataFrame():\n",
    "    raw_ecommerce_company_data = {'Ecommerce Service Name':[],'Ecommerce Service URLs':[]}\n",
    "    ecommerce_df = pd.DataFrame(raw_ecommerce_company_data)\n",
    "\n",
    "    for service in ecommerce_services_list.split():\n",
    "        ecommerce_df = ecommerce_df.append({'Ecommerce Service Name':service,'Ecommerce Service URLs':getURL(service)},ignore_index=True)\n",
    "    return ecommerce_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    # this gets the similarity between two key words\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getURL(search_query,link_limit = 100,correlation_tolerance=0.6):\n",
    "    \n",
    "    #This gets the first set of URLs that correspond to a service.\n",
    "    # The use is that we can iteratively go through a list of Ecommerce Services, and quickly find websites that relate to them\n",
    "    # the correlation tolerance needs to be quite specific because the search results may not always be super relevant\n",
    "  \n",
    "    domain_list = \"\"\n",
    "    ecommerce_likely_domains = \"\"\n",
    "    \n",
    "    page = requests.get(f\"https://www.google.co.uk/search?q={search_query}\")\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    links = soup.findAll(search_query)\n",
    " \n",
    "        \n",
    "\n",
    "    for link in soup.find_all(\"a\",href=re.compile(\"(?<=/url\\?q=)(htt.*://.*)\")):\n",
    "        link = re.split(\":(?=http)\",link[\"href\"].replace(\"/url?q=\",\"\"))\n",
    "        domain_list += link[0].split(\"//\")[-1].split(\"/\")[0] + \", \"\n",
    "    \n",
    "    domain_list = domain_list.split(\",\")\n",
    "    \n",
    "    for x in range(0,len(domain_list)):\n",
    "        compared = similar(search_query,domain_list[x])\n",
    "        if (compared> correlation_tolerance) or (search_query.lower() in domain_list[x].lower()):\n",
    "             ecommerce_likely_domains += domain_list[x] + \", \"\n",
    "    \n",
    "            \n",
    "    \n",
    "    return ' '.join(set(ecommerce_likely_domains.split()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addClientToDataFrame(our_company_name,our_company_url, has_ecommerce):\n",
    "    return df.append({'Our Company Name':our_company_name,'Our Company URL': our_company_url,'Has Ecommerce':has_ecommerce},ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkURLComponents(url):\n",
    "    just_domain_body=False\n",
    "    \n",
    "    domain_body_score = 0\n",
    "    domain_suffix_score = 0\n",
    "    domain_tail_score = 0\n",
    "    \n",
    "#     domain_ip = \"null\"\n",
    "    \n",
    "    \n",
    "\n",
    "    for word in list_stores:\n",
    "        if word.lower() in url.lower():\n",
    "                domain_body_score +=1\n",
    "                break\n",
    "\n",
    "    \n",
    "#     if (just_domain_body == True):\n",
    "#         return domain_body_score\n",
    "#     else:\n",
    "#         url = url.replace(\"https://\",\"\").replace(\"http://\",\"\").replace(\"/\",\"\").replace(\"www.\",\"\")\n",
    "#         print(url)\n",
    "        \n",
    "      \n",
    "\n",
    "\n",
    "#         for word in list_stores:\n",
    "#             print(\"working on:\")\n",
    "#             print(\"www.\" + url.split(\".\")[0] + \".\" + word)\n",
    "#             print(\"www.\" + url + \"/\" + word)\n",
    "   \n",
    "\n",
    "#             try:\n",
    "              \n",
    "#                 domain_ip = socket.gethostbyname(\"www.\" + url + \"/\" + word)\n",
    "#                 print(domain_ip + socket.gethostbyname(url + \"/\" + word))\n",
    "#                 if (socket.gethostbyname(url + \"/\" + word)):\n",
    "#                     print(\"yes\")\n",
    "#                 if (domain_ip != \"null\"):\n",
    "#                     print(url + word)\n",
    "#                     domain_suffix_score +=1\n",
    "#                     break\n",
    "#             except:\n",
    "#                 pass\n",
    "                \n",
    "#             try:\n",
    "               \n",
    "#                 domain_ip = \"null\"\n",
    "#                 domain_ip = socket.gethostbyname(\"www.\" + url.split(\".\")[0] + \".\" + word)\n",
    "              \n",
    "                \n",
    "        \n",
    "#                 if (domain_ip != \"null\"):\n",
    "#                     domain_tail_score += 1 \n",
    "#                     print(url + \"found a match with \" + \" \" +word)\n",
    "#                     break\n",
    "\n",
    "\n",
    "#             except:\n",
    "#                 pass\n",
    "                \n",
    "#         print(\"db \" + str(domain_body_score) + \"dss \" + str(domain_suffix_score) + \" dts \" + str(domain_tail_score))\n",
    "    return (domain_body_score + domain_suffix_score + domain_tail_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEcommerceTagScore(soup):\n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    for row in ecommerce_df[['Ecommerce Service Name','Ecommerce Service URLs']].iterrows():\n",
    "        for item in row[1]:\n",
    "            if item.lower() in soup.lower():\n",
    "             \n",
    "                score += 1\n",
    "                break\n",
    "\n",
    "\n",
    "        # this means that the appearance of each company, whether a keyword or url, will only increment score by one even if they're both added\n",
    "     \n",
    "    return score\n",
    "        \n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBuiltWithEcommerceScore(url):\n",
    "    score = 0\n",
    "    builtwith_analysis = builtwith.builtwith(url)\n",
    "    \n",
    "    builtwith_as_text = ''.join('{}{}'.format(key, val) for key, val in builtwith_analysis.items())\n",
    "    \n",
    "    ## possibly include more general keywords like ecommerce\n",
    "  \n",
    "    \n",
    "    for row in ecommerce_df[['Ecommerce Service Name','Ecommerce Service URLs']].iterrows():\n",
    "        for item in row[1]:\n",
    "            if item.lower() in builtwith_as_text.lower():\n",
    "                score += 1\n",
    "       \n",
    "              \n",
    "                break\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEcommerceIPsScore(desired_domain):\n",
    "    \n",
    "    score = 0\n",
    "    desired_domain = desired_domain.replace(\"https://\",\"\").replace(\"http://\",\"\").replace(\"/\",\"\")\n",
    " \n",
    "    \n",
    "    try:\n",
    "        domain_ip = socket.gethostbyname(desired_domain)\n",
    "     \n",
    "        domain_lookup = \"https://db-ip.com/\"\n",
    "    \n",
    "        agent = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'}\n",
    "        #The agent parameter is needed to create a \"user\" and to avoid any bot banning\n",
    "    \n",
    "    \n",
    "        page = requests.get(domain_lookup+domain_ip,headers=agent)\n",
    "        soup = BeautifulSoup(page.content)\n",
    "\n",
    "    \n",
    "        for row in ecommerce_df[['Ecommerce Service Name','Ecommerce Service URLs']].iterrows():\n",
    "            for item in row[1]:\n",
    "                if item.lower() in soup.text.lower():\n",
    "\n",
    "                    score += 1\n",
    "                    break\n",
    "\n",
    "\n",
    "        # this means that the appearance of each company, whether a keyword or url, will only increment score by one even if they're both added\n",
    "    except:\n",
    "        score = 0\n",
    "    return score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeyWordsScore(df):\n",
    " \n",
    "     \n",
    "    \n",
    "    \n",
    "    def getSocialMediaScore(social_media_content):\n",
    "        social_media_score = 0\n",
    "        for word in social_media_keywords:\n",
    "            if word.lower() in cleanText(social_media_content):\n",
    "                social_media_score+=2\n",
    "            if (word == \"twitter\"):\n",
    "                social_media_score+=4 \n",
    "        return social_media_score\n",
    "    \n",
    "    \n",
    "    def getPositiveWordScore(positive_content):\n",
    "        positive_word_score = 0\n",
    "        for word in positive_keywords:\n",
    "            if word.lower() in cleanText(positive_content):\n",
    "                positive_word_score +=3\n",
    "            if positive_word_score >= 10:\n",
    "                positive_word_score = 10\n",
    "        return positive_word_score \n",
    "    \n",
    "    def getNegativeWordScore(negative_content):\n",
    "        negative_word_score = 0\n",
    "        for word in black_list_keywords:\n",
    "            if word.lower() in cleanText(negative_content):\n",
    "                negative_word_score+=1\n",
    "        return negative_word_score\n",
    "    \n",
    "    \n",
    "    \n",
    "    df['Social_Media_Score'] = df['Text from Website'].apply(getSocialMediaScore)\n",
    "    df['Positive_Keyword_Score'] = df['Text from Website'].apply(getPositiveWordScore)\n",
    "    df['Blacklist_Keyword_Score'] = df['Text from Website'].apply(getNegativeWordScore)\n",
    "    df = df.drop('Text from Website',axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    \n",
    "    #used for natural language processing such as Key Word detection\n",
    "    \n",
    "    from string import punctuation\n",
    "    text = text.lower().replace(\".\", \". \")\n",
    "    text = ''.join(char for char in text if char not in punctuation)\n",
    "    ##update to include the punctuation particular to online websites e.g TM\n",
    "\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getDiscountedPrice(df):\n",
    "#     temp_df = df.copy()\n",
    "#     temp_df['Discounted Price'] = temp_df['Base Price']\n",
    "#     value = 0\n",
    "#     index=0\n",
    "#     for row in temp_df.itertuples():\n",
    "#         multiplier = 0\n",
    "#         multiplier -= row[8] + row[11]\n",
    "#         multiplier += row[9] + row[10]\n",
    "#         value = row[12]\n",
    "#         score = ((value*(1 - (1/100 * multiplier))))\n",
    "#         index = row[0]\n",
    "#         temp_df['Discounted Price'][index] = score\n",
    "#     return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDiscountedPrice(df):\n",
    "    temp_df = df.copy()\n",
    "    value = 0\n",
    "    index=0\n",
    "    score= 0\n",
    "   \n",
    "    for row in temp_df.itertuples():\n",
    "        index = row[0]\n",
    "        hygiene_rating = 0\n",
    "        multiplier = 0\n",
    "\n",
    "        google_review_discount = 6*(df['Google Rating Aggregate'][index])\n",
    "        hygiene_rating = df['Hygiene Rating'][index]\n",
    "        \n",
    "        if (hygiene_rating!=0):\n",
    "            if (hygiene_rating <=3):\n",
    "                multiplier -= 100\n",
    "            elif (hygiene_rating==4):\n",
    "                mutiplier-=15             \n",
    "        multiplier -= (df['Blacklist_Keyword_Score'][index]+ df['Ecommerce Detection Total Score'][index])*2\n",
    "#   Here I have Weighted the negatives, so that they are more punishing\n",
    "        multiplier += ((df['Positive_Keyword_Score'][index]+ df['Social_Media_Score'][index]) + google_review_discount)\n",
    "        value = df['Base Price'][index]\n",
    "        multiplier = (100-multiplier)/100\n",
    "        temp_df['Discounted Price'][index] = value*multiplier\n",
    "\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getAggregateGoogleReviews(business_address=\"\",business_name=\"\"):\n",
    "    \n",
    "#     if (business_address==\"None\"):\n",
    "#         return \"None\"\n",
    "#     else:\n",
    "\n",
    "#         input_for_placesAPI = \"\"\n",
    "#         joint_details = business_name + \" \" + business_address\n",
    "#         length = len(joint_details.split(\" \")) \n",
    "#         print(joint_details)\n",
    "#         for x in range(0,length):\n",
    "#             print(joint_details.split(\" \")[x])\n",
    "#             input_for_placesAPI  += joint_details.split(\" \")[x]\n",
    "#             if (x != length-1 and length!=0):\n",
    "#                 input_for_placesAPI += \"%20\"\n",
    "#         link_to_ratings = f\"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={input_for_placesAPI}&inputtype=textquery&fields=photos,formatted_address,name,rating,opening_hours,geometry&key={MY_API_KEY}\"\n",
    "#         page = requests.get(link_to_ratings,headers=agent)\n",
    "#         soup = BeautifulSoup(page.content)\n",
    "#         text = soup.text\n",
    "#         for x in range(0,len(text.split(\" \"))):\n",
    "#             if (text.split(\" \")[x] == \"\\\"rating\\\"\"):\n",
    "#                 rating = text.split(\" \")[x+2].replace(\",\",\"\")\n",
    "#         return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGoogleRatings(df):\n",
    "    \n",
    "    \n",
    "    \n",
    "          \n",
    "    def getDataFromGooglePlaces(business_address=\"\",business_name=\"\"):  \n",
    "        resulting_rating = 0\n",
    "        if (business_address==\"None\"):\n",
    "            return 0\n",
    "        else:\n",
    "            print(\"doing it\")\n",
    "            input_for_placesAPI = \"\"\n",
    "            joint_details = business_name + \" \" + business_address\n",
    "            length = len(joint_details.split(\" \")) \n",
    "            print(joint_details)\n",
    "            for x in range(0,length):\n",
    "                print(joint_details.split(\" \")[x])\n",
    "                input_for_placesAPI  += joint_details.split(\" \")[x]\n",
    "                if (x != length-1 and length!=0):\n",
    "                    input_for_placesAPI += \"%20\"\n",
    "            link_to_ratings = f\"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={input_for_placesAPI}&inputtype=textquery&fields=photos,formatted_address,name,rating,opening_hours,geometry&key={MY_API_KEY}\"\n",
    "            page = requests.get(link_to_ratings,headers=agent)\n",
    "            soup = BeautifulSoup(page.content)\n",
    "            text = soup.text\n",
    "            if (\"REQUEST_DENIED\" in text):\n",
    "                return 0\n",
    "            for x in range(0,len(text.split(\" \"))):\n",
    "                if (text.split(\" \")[x] == \"\\\"rating\\\"\"):\n",
    "                    resulting_rating = text.split(\" \")[x+2].replace(\",\",\"\")\n",
    "            return resulting_rating\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    temp_df = df.copy()\n",
    "    rating = 0\n",
    "    index=0\n",
    "    for row in temp_df.itertuples():\n",
    "        index = row[0]\n",
    "        rating = getDataFromGooglePlaces(row[3] ,row[1])\n",
    "        temp_df['Google Rating Aggregate'][index] = rating  \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHygieneRating(df):\n",
    "  \n",
    "    def grabHygieneRatingFromPlaces(business_name,business_postcode):\n",
    "            business_name_length = len(business_name.split(\" \"))\n",
    "            business_postcode_length = len(business_postcode.split(\" \"))\n",
    "            formatted_business_name = \"\"\n",
    "            formatted_business_postcode = \"\"\n",
    "            \n",
    "            for x in range(0, business_name_length):\n",
    "                formatted_business_name += business_name.split(\" \")[x]\n",
    "                if (x != business_name_length-1 and business_name_length!=0):\n",
    "                    formatted_business_name += \"+\"\n",
    "                    \n",
    "            for x in range(0, business_postcode_length):\n",
    "                formatted_business_postcode += business_postcode.split(\" \")[x]\n",
    "                if (x !=  business_postcode_length-1 and business_postcode_length!=0):\n",
    "                    formatted_business_postcode += \"+\"\n",
    "        \n",
    "        \n",
    "            lookup = \"https://public.opendatasoft.com/api/records/1.0/search//?dataset=uk-food-hygiene-rating\"\n",
    "            lookup += f\"&q={formatted_business_name}\"\n",
    "            lookup += f\"&sort=scores_hygiene&refine.postcode={formatted_business_postcode}\"\n",
    "            page = requests.get(lookup,headers=agent)\n",
    "            soup = BeautifulSoup(page.content)\n",
    "            text = soup.text\n",
    "            rating = 0\n",
    "\n",
    "\n",
    "            for x in range(0,len(text.split(\" \"))):\n",
    "                if (text.split(\" \")[x] == \"\\\"scores_hygiene\\\":\"):\n",
    "                    rating = text.split(\" \")[x+1].replace(\",\",\"\").replace(\"\\\"\",\"\")\n",
    "              \n",
    "                    if (rating != 0):\n",
    "                        break\n",
    "               \n",
    "                if (text.split(\" \")[x] == \"\\\"ratingvalue\\\":\"):\n",
    "                    rating = text.split(\" \")[x+1].replace(\",\",\"\").replace(\"\\\"\",\"\")\n",
    "                \n",
    "                    if (rating != 0):\n",
    "                        break\n",
    "            return rating\n",
    "    temp_df = df.copy()\n",
    "    hygiene_rating = 0\n",
    "    index = 0\n",
    "    for row in temp_df.itertuples():\n",
    "        index = row[0]\n",
    "        #probably need to do \n",
    "        address = \" \".join(row[3].split(\" \")[-2:])\n",
    "        print(address)\n",
    "        print(row[1])\n",
    "        hygiene_rating = grabHygieneRatingFromPlaces(row[1],address)\n",
    "        temp_df['Hygiene Rating'][index] = hygiene_rating\n",
    "    return temp_df\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getHygieneRating(tempdf10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tempdf10 = list_of_df[1].copy()\n",
    "# tempdf10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing it\n",
      "Joe's Cafe Joe's Cafe, 24 Upper Hamilton Rd, Brighton BN1 5DF\n",
      "Joe's\n",
      "Cafe\n",
      "Joe's\n",
      "Cafe,\n",
      "24\n",
      "Upper\n",
      "Hamilton\n",
      "Rd,\n",
      "Brighton\n",
      "BN1\n",
      "5DF\n",
      "doing it\n",
      "Moksha Caffe 4-5 York Pl, Brighton BN1 4GU\n",
      "Moksha\n",
      "Caffe\n",
      "4-5\n",
      "York\n",
      "Pl,\n",
      "Brighton\n",
      "BN1\n",
      "4GU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunchaser\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing it\n",
      "Cafe Coho 83a Queens Rd, Brighton BN1 3XE\n",
      "Cafe\n",
      "Coho\n",
      "83a\n",
      "Queens\n",
      "Rd,\n",
      "Brighton\n",
      "BN1\n",
      "3XE\n",
      "doing it\n",
      "Lovefit 110 Queens Rd, Brighton BN1 3XF\n",
      "Lovefit\n",
      "110\n",
      "Queens\n",
      "Rd,\n",
      "Brighton\n",
      "BN1\n",
      "3XF\n",
      "doing it\n",
      "Cafe Coho Churchill Square Russell Pl, Brighton BN1 2RG\n",
      "Cafe\n",
      "Coho\n",
      "Churchill\n",
      "Square\n",
      "Russell\n",
      "Pl,\n",
      "Brighton\n",
      "BN1\n",
      "2RG\n",
      "BN1 5DF\n",
      "Joe's Cafe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunchaser\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BN1 4GU\n",
      "Moksha Caffe\n",
      "BN1 3XE\n",
      "Cafe Coho\n",
      "BN1 3XF\n",
      "Lovefit\n",
      "None\n",
      "Porter and York\n",
      "None\n",
      "Dineamic\n",
      "None\n",
      "Haus London\n",
      "None\n",
      "The Critical Slide Society\n",
      "None\n",
      "Studio Proper\n",
      "None\n",
      "Tluxe\n",
      "BN1 2RG\n",
      "Cafe Coho Churchill Square\n",
      "BN1 5DF\n",
      "Joe's Cafe\n",
      "BN1 4GU\n",
      "Moksha Caffe\n",
      "BN1 3XE\n",
      "Cafe Coho\n",
      "BN1 3XF\n",
      "Lovefit\n",
      "None\n",
      "Porter and York\n",
      "None\n",
      "Dineamic\n",
      "None\n",
      "Haus London\n",
      "None\n",
      "The Critical Slide Society\n",
      "None\n",
      "Studio Proper\n",
      "None\n",
      "Tluxe\n",
      "BN1 2RG\n",
      "Cafe Coho Churchill Square\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunchaser\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Sunchaser\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Sunchaser\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "ecommerce_df = generateEcommerceListDataFrame()\n",
    "df = generateCustomerListDataFrame(add_samples=True)\n",
    "df = analyseCustomerListDataFrame(df,add_colours=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Company URL</th>\n",
       "      <th>Company Address</th>\n",
       "      <th>Has Ecommerce</th>\n",
       "      <th>Ecommerce Tags Found Score</th>\n",
       "      <th>Ecommerce IPs Found Score</th>\n",
       "      <th>Builtwith's Ecommerce-Detection Score</th>\n",
       "      <th>Ecommerce Domain URL Component Score</th>\n",
       "      <th>Ecommerce Detection Total Score</th>\n",
       "      <th>Google Rating Aggregate</th>\n",
       "      <th>Hygiene Rating</th>\n",
       "      <th>Social_Media_Score</th>\n",
       "      <th>Positive_Keyword_Score</th>\n",
       "      <th>Blacklist_Keyword_Score</th>\n",
       "      <th>Base Price</th>\n",
       "      <th>Discounted Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Joe's Cafe</td>\n",
       "      <td>http://www.joescafebrighton.com/</td>\n",
       "      <td>Joe's Cafe, 24 Upper Hamilton Rd, Brighton BN1...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3571</td>\n",
       "      <td>3213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Moksha Caffe</td>\n",
       "      <td>https://mokshacaffe.co.uk/</td>\n",
       "      <td>4-5 York Pl, Brighton BN1 4GU</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3571</td>\n",
       "      <td>3142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Cafe Coho</td>\n",
       "      <td>https://www.cafecoho.co.uk/</td>\n",
       "      <td>83a Queens Rd, Brighton BN1 3XE</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3571</td>\n",
       "      <td>3321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Lovefit</td>\n",
       "      <td>https://www.lovefit.co.uk/</td>\n",
       "      <td>110 Queens Rd, Brighton BN1 3XF</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3571</td>\n",
       "      <td>3321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Porter and York</td>\n",
       "      <td>https://porterandyork.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3571</td>\n",
       "      <td>3428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Dineamic</td>\n",
       "      <td>https://www.dineamic.com.au/</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3571</td>\n",
       "      <td>3356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Haus London</td>\n",
       "      <td>https://hauslondon.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3571</td>\n",
       "      <td>3642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>The Critical Slide Society</td>\n",
       "      <td>https://www.thecriticalslidesociety.eu/</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3571</td>\n",
       "      <td>3285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Studio Proper</td>\n",
       "      <td>https://www.studioproper.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3571</td>\n",
       "      <td>3535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Tluxe</td>\n",
       "      <td>https://www.tluxe.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3571</td>\n",
       "      <td>3642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Cafe Coho Churchill Square</td>\n",
       "      <td>https://new.brighton-hove.gov.uk/</td>\n",
       "      <td>Russell Pl, Brighton BN1 2RG</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3571</td>\n",
       "      <td>3035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Company Name                              Company URL  \\\n",
       "0                   Joe's Cafe         http://www.joescafebrighton.com/   \n",
       "1                 Moksha Caffe               https://mokshacaffe.co.uk/   \n",
       "2                    Cafe Coho              https://www.cafecoho.co.uk/   \n",
       "3                      Lovefit               https://www.lovefit.co.uk/   \n",
       "4              Porter and York               https://porterandyork.com/   \n",
       "5                     Dineamic             https://www.dineamic.com.au/   \n",
       "6                  Haus London                  https://hauslondon.com/   \n",
       "7   The Critical Slide Society  https://www.thecriticalslidesociety.eu/   \n",
       "8                Studio Proper            https://www.studioproper.com/   \n",
       "9                        Tluxe                   https://www.tluxe.com/   \n",
       "10  Cafe Coho Churchill Square        https://new.brighton-hove.gov.uk/   \n",
       "\n",
       "                                      Company Address  Has Ecommerce  \\\n",
       "0   Joe's Cafe, 24 Upper Hamilton Rd, Brighton BN1...          False   \n",
       "1                       4-5 York Pl, Brighton BN1 4GU           True   \n",
       "2                     83a Queens Rd, Brighton BN1 3XE           True   \n",
       "3                     110 Queens Rd, Brighton BN1 3XF          False   \n",
       "4                                                None           True   \n",
       "5                                                None           True   \n",
       "6                                                None           True   \n",
       "7                                                None           True   \n",
       "8                                                None           True   \n",
       "9                                                None           True   \n",
       "10                       Russell Pl, Brighton BN1 2RG          False   \n",
       "\n",
       "    Ecommerce Tags Found Score  Ecommerce IPs Found Score  \\\n",
       "0                            0                          0   \n",
       "1                            1                          0   \n",
       "2                            1                          0   \n",
       "3                            0                          0   \n",
       "4                            1                          0   \n",
       "5                            2                          1   \n",
       "6                            2                          1   \n",
       "7                            2                          1   \n",
       "8                            2                          1   \n",
       "9                            2                          1   \n",
       "10                           0                          1   \n",
       "\n",
       "    Builtwith's Ecommerce-Detection Score  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       1   \n",
       "3                                       0   \n",
       "4                                       1   \n",
       "5                                       1   \n",
       "6                                       1   \n",
       "7                                       1   \n",
       "8                                       1   \n",
       "9                                       1   \n",
       "10                                      0   \n",
       "\n",
       "    Ecommerce Domain URL Component Score  Ecommerce Detection Total Score  \\\n",
       "0                                      0                                0   \n",
       "1                                      0                                1   \n",
       "2                                      0                                2   \n",
       "3                                      0                                0   \n",
       "4                                      0                                2   \n",
       "5                                      0                                4   \n",
       "6                                      0                                4   \n",
       "7                                      0                                4   \n",
       "8                                      0                                4   \n",
       "9                                      0                                4   \n",
       "10                                     0                                1   \n",
       "\n",
       "   Google Rating Aggregate  Hygiene Rating  Social_Media_Score  \\\n",
       "0                     None               5                   4   \n",
       "1                     None               0                   8   \n",
       "2                     None               5                   8   \n",
       "3                     None               0                   4   \n",
       "4                     None               0                   8   \n",
       "5                     None               0                  10   \n",
       "6                     None               0                   8   \n",
       "7                     None               0                  10   \n",
       "8                     None               0                   8   \n",
       "9                     None               0                   8   \n",
       "10                    None               0                   8   \n",
       "\n",
       "    Positive_Keyword_Score  Blacklist_Keyword_Score  Base Price  \\\n",
       "0                        6                        0        3571   \n",
       "1                        6                        0        3571   \n",
       "2                        3                        0        3571   \n",
       "3                        3                        0        3571   \n",
       "4                        0                        0        3571   \n",
       "5                        6                        1        3571   \n",
       "6                        0                        1        3571   \n",
       "7                        6                        0        3571   \n",
       "8                        3                        1        3571   \n",
       "9                        0                        1        3571   \n",
       "10                       9                        0        3571   \n",
       "\n",
       "    Discounted Price  \n",
       "0               3213  \n",
       "1               3142  \n",
       "2               3321  \n",
       "3               3321  \n",
       "4               3428  \n",
       "5               3356  \n",
       "6               3642  \n",
       "7               3285  \n",
       "8               3535  \n",
       "9               3642  \n",
       "10              3035  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
